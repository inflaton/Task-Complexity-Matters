# Explainable Sentiment Analysis Dataset

## Description
This dataset contains annotated sentiment analysis data for **Amazon Reviews** and **IMDB Movie Reviews**, designed for evaluating and comparing sentiment classification performance across various large language models (LLMs). It includes **raw sentiment labels**, **model-generated predictions**, and **fine-grained classification results** from different models.

---

## Dataset Structure
The dataset is organized into two main directories:

### 1. `ground-truths/` – Labeled datasets for model evaluation
- `amazon_reviews.csv` – Complete dataset of Amazon Reviews with sentiment labels.
- `amazon_reviews-train.csv` – Training subset of Amazon Reviews.
- `amazon_reviews-test.csv` – Test subset of Amazon Reviews.
- `imdb_reviews.csv` – Complete dataset of IMDB Movie Reviews with sentiment labels.
- `imdb_reviews-train.csv` – Training subset of IMDB Reviews.
- `imdb_reviews-test.csv` – Test subset of IMDB Reviews.

### 2. `results/` – Sentiment classification results from various LLMs on test sets
- `amazon_reviews_results-API.csv` – Predictions from an external API-based LLM.
- `amazon_reviews_results-Ollama.csv` – Predictions from an open-source **Ollama-based** LLM.
- `imdb_reviews_results-Ollama.csv` – Predictions from an open-source **Ollama-based** LLM on the IMDB dataset.
- `imdb_reviews_results-API.csv` – Predictions from an external API-based LLM.

---

## Data Fields

Each **ground-truth** CSV file contains the following fields:

- **`Text`** – The full text of the review.
- **`Review-sentiment`** – The ground-truth **5-level sentiment label** (`Strongly Negative`, `Negative`, `Neutral`, `Positive`, `Strongly Positive`); available for Amazon Reviews only.
- **`Review-basic-sentiment`** – The **simplified sentiment label**:  
  - **Amazon Reviews:** 3-level classification (`Negative`, `Neutral`, `Positive`).  
  - **IMDB Reviews:** Binary classification (`Negative`, `Positive`).

Each **results** CSV file contains additional fields representing **model-generated outputs**, formatted as follows: {model_name}/shots-{shot_number:02d}({mean_eval_time:.3f})

where:
- `{model_name}` – The name of the LLM used.
- `{shot_number}` – The number of few-shot examples provided.
- `{mean_eval_time}` – The average inference time in seconds.

## LLM Result Format

The LLM result is a structured dump of a Python dictionary with the following format:

```python
{
  "content": {
    "sentiment": "predicted_sentiment",
    "explanation": "LLM-generated explanation"
  },
  "reasoning_content": "optional reasoning content from LLM"
}
```

Explanation of Fields:
- content: Contains the predicted sentiment and a brief explanation generated by the LLM.
- reasoning_content: Includes detailed reasoning steps from DeepSeek-R1 models. (This field is not available for OpenAI models.)

---

## Instructions for Use

### 1. Understanding the Data
- The **`ground-truths/`** folder contains labeled sentiment datasets for training and benchmarking models.
- The **`results/`** folder provides LLM-generated sentiment predictions, allowing users to compare model performance.

### 2. Using the Data for Evaluation
Load any CSV file using Python’s Pandas library:

```python
import pandas as pd
df = pd.read_csv("path/to/file.csv")
print(df.head())
